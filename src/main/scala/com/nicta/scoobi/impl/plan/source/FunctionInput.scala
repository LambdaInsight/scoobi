/**
 * Copyright 2011,2012 National ICT Australia Limited
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
package com.nicta.scoobi
package impl
package plan
package source

import java.io.DataInput
import java.io.DataOutput
import java.io.ObjectInputStream
import java.io.ObjectOutputStream
import java.io.ByteArrayInputStream
import java.io.ByteArrayOutputStream
import org.apache.commons.logging.LogFactory
import org.apache.hadoop.io.Writable
import org.apache.hadoop.io.NullWritable
import org.apache.hadoop.mapreduce.InputFormat
import org.apache.hadoop.mapreduce.InputSplit
import org.apache.hadoop.mapreduce.RecordReader
import org.apache.hadoop.mapreduce.TaskAttemptContext
import org.apache.hadoop.mapreduce.Job
import org.apache.hadoop.mapreduce.JobContext
import scala.collection.JavaConversions._

import core._
import impl._
import Configurations._
import impl.collection.Seqs._
import impl.collection.FunctionBoundedLinearSeq
import plan.DListImpl
import com.nicta.scoobi.impl.util.{Compatibility, DistCache}
import FunctionInput._
import org.apache.hadoop.fs.Path

/** Smart function for creating a distributed lists from a Scala function. */
trait FunctionInput {
  lazy val logger = LogFactory.getLog("scoobi.FunctionInput")

  /** Create a distributed list of a specified length whose elements are generated by
    * a function that maps list indices to element values. */
  def fromFunction[A : WireFormat](n: Int)(f: Int => A): DList[A] = {
    val source = new DataSource[NullWritable, A, A] {

      val inputFormat = classOf[FunctionInputFormat[A]]
      override def toString = "FunctionInput("+id+")"

      def inputCheck(implicit sc: ScoobiConfiguration) {}

      def inputConfigure(job: Job)(implicit sc: ScoobiConfiguration) {
        job.getConfiguration.setInt(LengthProperty, n)
        /* Because FunctionInputFormat is shared between multiple instances of the Function
         * DataSource, each must have a unique id to distinguish their serialised
         * functions that are pushed out by the distributed cache.
         * Note that the previous function Id might have been set on a key such as "scoobi.input0:scoobi.function.id"
         * This is why we need to look for keys by regular expression in order to find the maximum value to increment
         */
        DistCache.pushObject(job.getConfiguration, f, functionProperty(job.getConfiguration.incrementRegex(IdProperty, ".*"+IdProperty)))
      }

      def inputSize(implicit sc: ScoobiConfiguration): Long = n.toLong

      lazy val inputConverter = new InputConverter[NullWritable, A, A] {
        def fromKeyValue(context: InputContext, k: NullWritable, v: A) = v
      }
    }
    DListImpl(source)
  }

}

object FunctionInput extends FunctionInput {
  /* Configuration property names. */
  val PropertyPrefix = "scoobi.function"
  val LengthProperty = PropertyPrefix + ".n"
  val IdProperty = PropertyPrefix + ".id"
  def functionProperty(id: Int) = PropertyPrefix + ".f" + id
}

/** InputFormat for producing values based on a function. */
class FunctionInputFormat[A] extends InputFormat[NullWritable, A] {
  lazy val logger = LogFactory.getLog("scoobi.FunctionInput")

  def createRecordReader(split: InputSplit, context: TaskAttemptContext): RecordReader[NullWritable, A] =
    new FunctionRecordReader[A](split.asInstanceOf[FunctionInputSplit[A]])

  def getSplits(context: JobContext): java.util.List[InputSplit] = {
    val conf = Compatibility.getConfiguration(context)
    val n    = conf.getInt(LengthProperty, 0)
    val id   = conf.getInt(IdProperty, 0)

    val f = DistCache.pullObject[Int => A](conf, functionProperty(id)).getOrElse((i:Int) => sys.error("no function found in the distributed cache for: "+functionProperty(id)))

    val numSplitsHint = conf.getInt("mapred.map.tasks", 1)
    val splitSize = n / numSplitsHint

    logger.debug("id=" + id)
    logger.debug("n=" + n)
    logger.debug("numSplitsHint=" + numSplitsHint)
    logger.debug("splitSize=" + splitSize)

    val cacheFiles = DistCache.localCacheFiles(conf) ++ DistCache.cacheFiles(conf)
    val path = DistCache.tagToPath(conf, functionProperty(id))

    split(f, splitSize, (offset: Int, length: Int, fs: Int => A) =>
      new FunctionInputSplit(offset, length, cacheFiles, path))(FunctionBoundedLinearSeq(_, n))
  }
}


/** InputSplit for a range of values produced by a function. */
class FunctionInputSplit[A](var start: Int, var length: Int, var cacheFiles: Array[Path], var path: Path) extends InputSplit with Writable {

  lazy val function =
    DistCache.pullObject[Int => A](cacheFiles, path).
      getOrElse((i:Int) => sys.error("no function found in the distributed cache: "+cacheFiles.mkString(",")))

  def this() = this(0, 0, Array(), null)

  def getLength: Long = length.toLong

  def getLocations: Array[String] = new Array[String](0)

  def readFields(in: DataInput) = {
    start = in.readInt()
    length = in.readInt()

    val cacheSize = in.readInt()
    cacheFiles = new Array[Path](cacheSize)
    (0 until cacheSize).foreach(i => cacheFiles(i) = new Path(in.readUTF))

    path = new Path(in.readUTF())
  }

  def write(out: DataOutput) = {
    out.writeInt(start)
    out.writeInt(length)

    out.writeInt(cacheFiles.size)
    cacheFiles.foreach(f => out.writeUTF(f.toString))

    out.writeUTF(path.toString)
  }
}


/** RecordReader for producing values based on a function. */
class FunctionRecordReader[A](split: FunctionInputSplit[A]) extends RecordReader[NullWritable, A] {

  private val end = split.start + split.length
  private var ix = split.start
  private var x: A = _

  def initialize(split: InputSplit, context: TaskAttemptContext) = {}

  def getCurrentKey(): NullWritable = NullWritable.get

  def getCurrentValue(): A = x

  def getProgress(): Float = (ix - (end - split.length)) / split.length

  def nextKeyValue(): Boolean = {
    if (ix < end) {
      x = split.function(ix)
      ix += 1
      true
    } else {
      false
    }
  }

  def close() = {}
}